{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Projecy: Prediction Delivery Time For Online Shopping\n",
    "\n",
    "Huy Hoang Vuong | June 25, 2023\n",
    "\n",
    "This Project is focused on predicting the estimated delivery time for the online shopping order, which helps to improve the customer experience by assisting them to answer the question: \"When do I get my order ?\" as close as possible.\n",
    "\n",
    "***Please Note:*** This is Notebook 2 of 2 that is used to do feature selection, design model, run, evaluate and optimize models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#Model Import\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#preprocessing import\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b2c_c2c</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>declared_handling_days</th>\n",
       "      <th>acceptance_scan_timestamp</th>\n",
       "      <th>shipment_method_id</th>\n",
       "      <th>shipping_fee</th>\n",
       "      <th>carrier_min_estimate</th>\n",
       "      <th>carrier_max_estimate</th>\n",
       "      <th>item_zip</th>\n",
       "      <th>buyer_zip</th>\n",
       "      <th>category_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>payment_datetime</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>weight</th>\n",
       "      <th>weight_units</th>\n",
       "      <th>package_size</th>\n",
       "      <th>record_number</th>\n",
       "      <th>distance</th>\n",
       "      <th>handling_date</th>\n",
       "      <th>shipping_date</th>\n",
       "      <th>total_time</th>\n",
       "      <th>pay_year</th>\n",
       "      <th>pay_month</th>\n",
       "      <th>pay_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2C</td>\n",
       "      <td>25454</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>97219</td>\n",
       "      <td>49040</td>\n",
       "      <td>13</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>LETTER</td>\n",
       "      <td>1</td>\n",
       "      <td>3002.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C2C</td>\n",
       "      <td>6727381</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11415-3528</td>\n",
       "      <td>62521</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PACKAGE_THICK_ENVELOPE</td>\n",
       "      <td>2</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B2C</td>\n",
       "      <td>18507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27292</td>\n",
       "      <td>53010</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>PACKAGE_THICK_ENVELOPE</td>\n",
       "      <td>3</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B2C</td>\n",
       "      <td>4677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90703</td>\n",
       "      <td>80022</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>PACKAGE_THICK_ENVELOPE</td>\n",
       "      <td>4</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B2C</td>\n",
       "      <td>4677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-07-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90703</td>\n",
       "      <td>55070</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>PACKAGE_THICK_ENVELOPE</td>\n",
       "      <td>5</td>\n",
       "      <td>2456.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  b2c_c2c  seller_id  declared_handling_days acceptance_scan_timestamp  \\\n",
       "0     B2C      25454                     3.0                2019-03-27   \n",
       "1     C2C    6727381                     2.0                2018-06-03   \n",
       "2     B2C      18507                     1.0                2019-01-08   \n",
       "3     B2C       4677                     1.0                2018-12-18   \n",
       "4     B2C       4677                     1.0                2018-07-28   \n",
       "\n",
       "   shipment_method_id  shipping_fee  carrier_min_estimate  \\\n",
       "0                   0           0.0                   3.0   \n",
       "1                   0           3.0                   3.0   \n",
       "2                   0           4.0                   3.0   \n",
       "3                   0           0.0                   3.0   \n",
       "4                   0           0.0                   3.0   \n",
       "\n",
       "   carrier_max_estimate    item_zip buyer_zip  category_id  item_price  \\\n",
       "0                   5.0       97219     49040           13        28.0   \n",
       "1                   5.0  11415-3528     62521            0        20.0   \n",
       "2                   5.0       27292     53010            1        20.0   \n",
       "3                   5.0       90703     80022            1        36.0   \n",
       "4                   5.0       90703     55070            1        25.0   \n",
       "\n",
       "   quantity payment_datetime delivery_date  weight  weight_units  \\\n",
       "0         1       2019-03-24    2019-03-29       5             1   \n",
       "1         1       2018-06-02    2018-06-05       0             1   \n",
       "2         1       2019-01-06    2019-01-10       9             1   \n",
       "3         1       2018-12-17    2018-12-21       8             1   \n",
       "4         1       2018-07-27    2018-07-30       3             1   \n",
       "\n",
       "             package_size  record_number  distance  handling_date  \\\n",
       "0                  LETTER              1    3002.0              3   \n",
       "1  PACKAGE_THICK_ENVELOPE              2    1283.0              1   \n",
       "2  PACKAGE_THICK_ENVELOPE              3    1104.0              2   \n",
       "3  PACKAGE_THICK_ENVELOPE              4    1353.0              1   \n",
       "4  PACKAGE_THICK_ENVELOPE              5    2456.0              1   \n",
       "\n",
       "   shipping_date  total_time  pay_year  pay_month  pay_date  \n",
       "0              2           5      2019          3        24  \n",
       "1              2           3      2018          6         2  \n",
       "2              2           4      2019          1         6  \n",
       "3              3           4      2018         12        17  \n",
       "4              2           3      2018          7        27  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebay_clean= pd.read_csv('../data/cleaned/Ebay_cleaned.csv', index_col=0)\n",
    "pd.set_option('display.max_columns', None)\n",
    "ebay_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b2c_c2c                      0\n",
       "seller_id                    0\n",
       "declared_handling_days       0\n",
       "acceptance_scan_timestamp    0\n",
       "shipment_method_id           0\n",
       "shipping_fee                 0\n",
       "carrier_min_estimate         0\n",
       "carrier_max_estimate         0\n",
       "item_zip                     0\n",
       "buyer_zip                    0\n",
       "category_id                  0\n",
       "item_price                   0\n",
       "quantity                     0\n",
       "payment_datetime             0\n",
       "delivery_date                0\n",
       "weight                       0\n",
       "weight_units                 0\n",
       "package_size                 0\n",
       "record_number                0\n",
       "distance                     0\n",
       "handling_date                0\n",
       "shipping_date                0\n",
       "total_time                   0\n",
       "pay_year                     0\n",
       "pay_month                    0\n",
       "pay_date                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebay_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 493951 entries, 0 to 499999\n",
      "Data columns (total 26 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   b2c_c2c                    493951 non-null  object \n",
      " 1   seller_id                  493951 non-null  int64  \n",
      " 2   declared_handling_days     493951 non-null  float64\n",
      " 3   acceptance_scan_timestamp  493951 non-null  object \n",
      " 4   shipment_method_id         493951 non-null  int64  \n",
      " 5   shipping_fee               493951 non-null  float64\n",
      " 6   carrier_min_estimate       493951 non-null  float64\n",
      " 7   carrier_max_estimate       493951 non-null  float64\n",
      " 8   item_zip                   493951 non-null  object \n",
      " 9   buyer_zip                  493951 non-null  object \n",
      " 10  category_id                493951 non-null  int64  \n",
      " 11  item_price                 493951 non-null  float64\n",
      " 12  quantity                   493951 non-null  int64  \n",
      " 13  payment_datetime           493951 non-null  object \n",
      " 14  delivery_date              493951 non-null  object \n",
      " 15  weight                     493951 non-null  int64  \n",
      " 16  weight_units               493951 non-null  int64  \n",
      " 17  package_size               493951 non-null  object \n",
      " 18  record_number              493951 non-null  int64  \n",
      " 19  distance                   493951 non-null  float64\n",
      " 20  handling_date              493951 non-null  int64  \n",
      " 21  shipping_date              493951 non-null  int64  \n",
      " 22  total_time                 493951 non-null  int64  \n",
      " 23  pay_year                   493951 non-null  int64  \n",
      " 24  pay_month                  493951 non-null  int64  \n",
      " 25  pay_date                   493951 non-null  int64  \n",
      "dtypes: float64(6), int64(13), object(7)\n",
      "memory usage: 101.8+ MB\n"
     ]
    }
   ],
   "source": [
    "ebay_clean.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare feature and target columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= ebay_clean[['b2c_c2c', 'declared_handling_days', 'shipment_method_id', 'shipping_fee', 'item_price', 'weight', 'package_size', 'distance']]\n",
    "y= ebay_clean['total_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(493951,)\n",
      "(493951, 8)\n"
     ]
    }
   ],
   "source": [
    "#Check shape \n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "X_train_ss= scaler.fit_transform(X_train, y_train)\n",
    "X_test_ss= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get value of y train and test to use in the accuracy function\n",
    "y_true_test= y_test.values\n",
    "y_true_train= y_train.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_late(y_actual, pred):\n",
    "    '''\n",
    "        This function is used to calculate the accuracy of the model in the different aspects:\n",
    "       When the model runs, the accuracy will calculate the exact match number for the true prediction; the prediction given late or early delivery will be counted as false.\n",
    "       But from the business point of view, The order delivered earlier than the prediction will not get any complaint from a customer and will be considered an on-time delivery.\n",
    "       In this function, we will modify the accuracy of the model base on the logic above:\n",
    "           day predict > actual delivered: Ontime\n",
    "           day predict = actual predictions: Ontime\n",
    "           day predict < actual delivered: Late\n",
    "    '''\n",
    "    ontime= 0\n",
    "    late= 0\n",
    "    accuracy_sc=0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == y_actual[i] or pred[i]> y_actual[i]:\n",
    "            ontime+=1\n",
    "        else:\n",
    "            late+=1\n",
    "    accuracy_sc= ontime/len(y_actual)*100\n",
    "    return accuracy_sc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss Function Calulate**\n",
    "\n",
    "The loss function was provide by the organizer.\n",
    "$$L = \\frac{1}{N}.abs([P_E.\\sum_{early shipments}(actual delivery days - predicted deliveryday)+ P_L.\\sum_{late shipments}(actual delivery days - predicted deliveryday)])$$\n",
    "while $P_E = 0.4$, $P_L = 0.6$ and N is number of record in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(preds, actual):\n",
    "    ''''\n",
    "        This Loss function was provided by the eBay team, who was given out the dataset for their Machine learning challenge.\n",
    "        From a business point of view, it is a worse experience for a buyer if a shipment arrives after the estimated delivery date (“late shipment”) \n",
    "            as compared to arriving before the estimated delivery date (“early shipment”). \n",
    "            The formula for the loss function was mentioned above.\n",
    "        \n",
    "    '''\n",
    "    early_loss, late_loss = 0,0 \n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] < actual[i]:\n",
    "            #early shipment\n",
    "            early_loss += actual[i] - preds[i]\n",
    "        elif preds[i] > actual[i]:\n",
    "            #late shipment\n",
    "            late_loss += preds[i] - actual[i]\n",
    "    loss = (1/len(preds)) * (0.4 * (early_loss) + 0.6 * (late_loss))\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize\n",
    "linear_model= LinearRegression()\n",
    "#fit model\n",
    "linear_model.fit(X_train_ss, y_train)\n",
    "#Predict\n",
    "linear_preds= linear_model.predict(X_test_ss)\n",
    "linear_train_pred= linear_model.predict(X_train_ss)\n",
    "#rouding\n",
    "linear_train_pred= np.round(linear_train_pred)\n",
    "linear_preds= np.round(linear_preds)\n",
    "linear_accuracy_test= define_late(y_true_test, linear_preds)\n",
    "linear_accuracy_train= define_late(y_true_train, linear_train_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score test:  70.61371987326781\n",
      "Linear regression Loss= 0.8006579546719841\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy score test:  {linear_accuracy_test}')\n",
    "#Loss Calculation\n",
    "print(f\"Linear regression Loss= {evaluate_loss(linear_preds, y_true_test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "ridge_model= Ridge(solver='lsqr')\n",
    "\n",
    "# fit\n",
    "ridge_model.fit(X_train_ss, y_train)\n",
    "#Predict and round\n",
    "ridge_preds= ridge_model.predict(X_test_ss)\n",
    "ridge_preds= np.round(ridge_preds)\n",
    "ridge_train_pred= ridge_model.predict(X_train_ss)\n",
    "ridge_train_pred= np.round(ridge_train_pred)\n",
    "\n",
    "#Calculate loss\n",
    "ridge_accuracy_test= define_late(y_true_test, ridge_preds)\n",
    "ridge_accuracy_train= define_late(y_true_train, ridge_train_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Accuracy score test:  70.61878106305231\n",
      "Ridge regression Loss= 0.8006822483829498\n"
     ]
    }
   ],
   "source": [
    "print(f'Ridge Accuracy score test:  {ridge_accuracy_test}')\n",
    "#Loss calculation\n",
    "print(f\"Ridge regression Loss= {evaluate_loss(ridge_preds, y_true_test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize \n",
    "xg_boost= XGBRegressor()\n",
    "#fit\n",
    "xg_boost.fit(X_train_ss, y_train)\n",
    "#Predict and round\n",
    "xg_pred= xg_boost.predict(X_test_ss)\n",
    "xg_pred= np.round(xg_pred)\n",
    "xg_train_pred= xg_boost.predict(X_train_ss)\n",
    "xg_train_pred= np.round(xg_train_pred)\n",
    "#Calculate accuracy\n",
    "xg_train_accuracy=define_late(y_true_train, xg_train_pred)\n",
    "xg_test_accuracy= define_late(y_true_test, xg_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate XGboost Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 71.60368859511495\n",
      "xgboost lost= 0.758265429037058\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy : {xg_test_accuracy}')\n",
    "#Loss calculate\n",
    "print(f'xgboost lost= {evaluate_loss(xg_pred, y_true_test)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "tf.random.set_seed(123)\n",
    "# Create a new sequential model\n",
    "nn_model= keras.Sequential()\n",
    "# regularizer= keras.regularizers.l2(0.02)\n",
    "#hidden layers\n",
    "nn_model.add(Dense(128, activation=\"relu\"))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(64, activation=\"relu\"))\n",
    "nn_model.add(Dense(32, activation=\"relu\"))\n",
    "# nn_model.add(Dropout(0.2))\n",
    "#output layer\n",
    "nn_model.add(Dense(1))\n",
    "\n",
    "#compile nn_model\n",
    "nn_model.compile(\n",
    "     optimizer=keras.optimizers.Adam(),\n",
    "     loss=keras.losses.MeanSquaredError(),\n",
    "     metrics=[keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= nn_model.fit(X_train_ss, y_train, epochs=50,batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3088/3088 [==============================] - 1s 210us/step\n",
      "12349/12349 [==============================] - 3s 210us/step\n"
     ]
    }
   ],
   "source": [
    "#predict \n",
    "NN_pred_test = np.round(nn_model.predict(X_test_ss))\n",
    "NN_pred_train = np.round(nn_model.predict(X_train_ss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Test Accuracy: 72.00352258809001\n",
      "Neural Network regression Loss= [0.75889915]\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural Network Test Accuracy: {define_late(y_true_test, NN_pred_test)}')\n",
    "#calculate Loss\n",
    "print(f\"Neural Network regression Loss= {evaluate_loss(NN_pred_test, y_true_test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recurrent Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395160, 8) (395160,)\n"
     ]
    }
   ],
   "source": [
    "#check Shape of feature and target\n",
    "print(X_train_ss.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding configure\n",
    "number_class= X_train_ss.shape[1]\n",
    "embedding_dim= 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "#define rnn\n",
    "rnn_mode= keras.Sequential()\n",
    "# add layers\n",
    "embedding_layer=Embedding(number_class, embedding_dim)\n",
    "\n",
    "rnn_mode.add(LSTM(64, activation='relu', input_shape=(X_train_ss.shape[1], 1)))\n",
    "\n",
    "rnn_mode.add(Dense(64, activation= 'relu'))\n",
    "\n",
    "#output layer\n",
    "rnn_mode.add(Dense(1))\n",
    "\n",
    "# Compile mode\n",
    "rnn_mode.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer=Adam(learning_rate=0.02),\n",
    "    metrics='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7199 - accuracy: 0.0304 - val_loss: 8.9697 - val_accuracy: 0.0300\n",
      "Epoch 2/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7204 - accuracy: 0.0304 - val_loss: 8.9522 - val_accuracy: 0.0300\n",
      "Epoch 3/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7204 - accuracy: 0.0304 - val_loss: 8.9437 - val_accuracy: 0.0300\n",
      "Epoch 4/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7207 - accuracy: 0.0304 - val_loss: 8.9438 - val_accuracy: 0.0300\n",
      "Epoch 5/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7211 - accuracy: 0.0304 - val_loss: 8.9437 - val_accuracy: 0.0300\n",
      "Epoch 6/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7207 - accuracy: 0.0304 - val_loss: 8.9502 - val_accuracy: 0.0300\n",
      "Epoch 7/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7206 - accuracy: 0.0304 - val_loss: 8.9513 - val_accuracy: 0.0300\n",
      "Epoch 8/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7217 - accuracy: 0.0304 - val_loss: 8.9441 - val_accuracy: 0.0300\n",
      "Epoch 9/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7201 - accuracy: 0.0304 - val_loss: 8.9555 - val_accuracy: 0.0300\n",
      "Epoch 10/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7209 - accuracy: 0.0304 - val_loss: 8.9503 - val_accuracy: 0.0300\n",
      "Epoch 11/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7206 - accuracy: 0.0304 - val_loss: 8.9441 - val_accuracy: 0.0300\n",
      "Epoch 12/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7208 - accuracy: 0.0304 - val_loss: 8.9509 - val_accuracy: 0.0300\n",
      "Epoch 13/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7212 - accuracy: 0.0304 - val_loss: 8.9437 - val_accuracy: 0.0300\n",
      "Epoch 14/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7206 - accuracy: 0.0304 - val_loss: 8.9676 - val_accuracy: 0.0300\n",
      "Epoch 15/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7207 - accuracy: 0.0304 - val_loss: 8.9439 - val_accuracy: 0.0300\n",
      "Epoch 16/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7201 - accuracy: 0.0304 - val_loss: 8.9522 - val_accuracy: 0.0300\n",
      "Epoch 17/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7208 - accuracy: 0.0304 - val_loss: 8.9611 - val_accuracy: 0.0300\n",
      "Epoch 18/50\n",
      "4940/4940 [==============================] - 12s 3ms/step - loss: 9.7208 - accuracy: 0.0304 - val_loss: 8.9461 - val_accuracy: 0.0300\n",
      "Epoch 19/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7208 - accuracy: 0.0304 - val_loss: 8.9462 - val_accuracy: 0.0300\n",
      "Epoch 20/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7212 - accuracy: 0.0304 - val_loss: 8.9512 - val_accuracy: 0.0300\n",
      "Epoch 21/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7208 - accuracy: 0.0304 - val_loss: 8.9472 - val_accuracy: 0.0300\n",
      "Epoch 22/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7207 - accuracy: 0.0304 - val_loss: 8.9561 - val_accuracy: 0.0300\n",
      "Epoch 23/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7209 - accuracy: 0.0304 - val_loss: 8.9439 - val_accuracy: 0.0300\n",
      "Epoch 24/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7199 - accuracy: 0.0304 - val_loss: 8.9452 - val_accuracy: 0.0300\n",
      "Epoch 25/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7201 - accuracy: 0.0304 - val_loss: 8.9446 - val_accuracy: 0.0300\n",
      "Epoch 26/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7204 - accuracy: 0.0304 - val_loss: 8.9647 - val_accuracy: 0.0300\n",
      "Epoch 27/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7214 - accuracy: 0.0304 - val_loss: 8.9439 - val_accuracy: 0.0300\n",
      "Epoch 28/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7208 - accuracy: 0.0304 - val_loss: 8.9437 - val_accuracy: 0.0300\n",
      "Epoch 29/50\n",
      "4940/4940 [==============================] - 12s 2ms/step - loss: 9.7212 - accuracy: 0.0304 - val_loss: 8.9488 - val_accuracy: 0.0300\n",
      "Epoch 30/50\n",
      "4940/4940 [==============================] - 12s 2ms/step - loss: 9.7205 - accuracy: 0.0304 - val_loss: 8.9464 - val_accuracy: 0.0300\n",
      "Epoch 31/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7206 - accuracy: 0.0304 - val_loss: 8.9442 - val_accuracy: 0.0300\n",
      "Epoch 32/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7206 - accuracy: 0.0304 - val_loss: 8.9444 - val_accuracy: 0.0300\n",
      "Epoch 33/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7202 - accuracy: 0.0304 - val_loss: 8.9484 - val_accuracy: 0.0300\n",
      "Epoch 34/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7204 - accuracy: 0.0304 - val_loss: 8.9450 - val_accuracy: 0.0300\n",
      "Epoch 35/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7203 - accuracy: 0.0304 - val_loss: 8.9514 - val_accuracy: 0.0300\n",
      "Epoch 36/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7214 - accuracy: 0.0304 - val_loss: 8.9662 - val_accuracy: 0.0300\n",
      "Epoch 37/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7208 - accuracy: 0.0304 - val_loss: 8.9452 - val_accuracy: 0.0300\n",
      "Epoch 38/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7211 - accuracy: 0.0304 - val_loss: 8.9523 - val_accuracy: 0.0300\n",
      "Epoch 39/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7213 - accuracy: 0.0304 - val_loss: 8.9463 - val_accuracy: 0.0300\n",
      "Epoch 40/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7213 - accuracy: 0.0304 - val_loss: 8.9546 - val_accuracy: 0.0300\n",
      "Epoch 41/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7210 - accuracy: 0.0304 - val_loss: 8.9448 - val_accuracy: 0.0300\n",
      "Epoch 42/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7205 - accuracy: 0.0304 - val_loss: 8.9452 - val_accuracy: 0.0300\n",
      "Epoch 43/50\n",
      "4940/4940 [==============================] - 12s 2ms/step - loss: 9.7202 - accuracy: 0.0304 - val_loss: 8.9441 - val_accuracy: 0.0300\n",
      "Epoch 44/50\n",
      "4940/4940 [==============================] - 12s 2ms/step - loss: 9.7206 - accuracy: 0.0304 - val_loss: 8.9459 - val_accuracy: 0.0300\n",
      "Epoch 45/50\n",
      "4940/4940 [==============================] - 12s 2ms/step - loss: 9.7208 - accuracy: 0.0304 - val_loss: 8.9472 - val_accuracy: 0.0300\n",
      "Epoch 46/50\n",
      "4940/4940 [==============================] - 12s 2ms/step - loss: 9.7209 - accuracy: 0.0304 - val_loss: 8.9442 - val_accuracy: 0.0300\n",
      "Epoch 47/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7207 - accuracy: 0.0304 - val_loss: 8.9439 - val_accuracy: 0.0300\n",
      "Epoch 48/50\n",
      "4940/4940 [==============================] - 12s 3ms/step - loss: 9.7202 - accuracy: 0.0304 - val_loss: 8.9502 - val_accuracy: 0.0300\n",
      "Epoch 49/50\n",
      "4940/4940 [==============================] - 13s 3ms/step - loss: 9.7203 - accuracy: 0.0304 - val_loss: 8.9437 - val_accuracy: 0.0300\n",
      "Epoch 50/50\n",
      "4940/4940 [==============================] - 12s 3ms/step - loss: 9.7210 - accuracy: 0.0304 - val_loss: 8.9438 - val_accuracy: 0.0300\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "rnn_history= rnn_mode.fit(X_train_ss, y_train, epochs=50, batch_size=64, validation_split=0.2, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3088/3088 [==============================] - 2s 518us/step\n",
      "12349/12349 [==============================] - 6s 518us/step\n"
     ]
    }
   ],
   "source": [
    "#Predict and rounding\n",
    "rnn_pred_test= np.round(rnn_mode.predict(X_test_ss))\n",
    "rnn_pred_train= np.round(rnn_mode.predict(X_train_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 64)                16896     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,121\n",
      "Trainable params: 21,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_mode.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  accuracy= 71.93873935884848\n",
      "Recurrent Neural Network Loss= [0.824561]\n"
     ]
    }
   ],
   "source": [
    "print(f'Test  accuracy= {define_late(y_true_test, rnn_pred_test)}')\n",
    "#loss calculation\n",
    "print(f\"Recurrent Neural Network Loss= {evaluate_loss(rnn_pred_test, y_true_test)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft Summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have tried : Linear Regression, Ridge regression, XGboost, Neural Network, and Recurrent Neural Network\n",
    "\n",
    "The score we have for each model is:\n",
    "\n",
    "  | Model | Accurancy Score | Loss | \n",
    "  | ----------- | ----------- |----|\n",
    "  | Linear Regression | 70.6137 |0.8007 |\n",
    "  | Ridge Regression | 70.6187 |0.8007 |\n",
    "  | XGboost | 71.6037 |0.7583 |\n",
    "  | Neural Network | 72.0035 |0.7589 |\n",
    "  | Recurrent Neural Network | 71.9387 |0.8246 |\n",
    "\n",
    "At the moment, Neural Network have the best accuracy for the datase with the `Loss= 0.7589`. Coming very close behind is Neural Network with the `Loss= 0.7589` and the accuracy is bit higher 72.0035 . We are going to do tune hyperparameter to see if we can reduce the `loss` of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Turning Hyperparameter for `Ridge` and `XGboost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimator\n",
    "estimators= [\n",
    "    ('normalise', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "] \n",
    "#Pipeline\n",
    "my_pipe= Pipeline(estimators)\n",
    "#Ridge\n",
    "grid1= [\n",
    "    {\n",
    "        'model': [Ridge()],\n",
    "        'normalise':[StandardScaler()],\n",
    "        'model__alpha':[0.001, 0.01, 0.1, 1],\n",
    "        'model__solver':['auto', ]\n",
    "    }]\n",
    "gridCV1= GridSearchCV(my_pipe, grid1, cv=5, verbose=0)\n",
    "fit_grid1= gridCV1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "grid2=[    \n",
    "    {\n",
    "        'model':[XGBRegressor()],\n",
    "        'normalise':[StandardScaler()],\n",
    "        'model__subsample': np.arange(0.1, 1, 0.2),\n",
    "        'model__max_depth': range (4, 12, 2),\n",
    "        'model__n_estimators': [60, 120, 180],\n",
    "        'model__learning_rate': [0.1, 0.01, 0.05]\n",
    "    }\n",
    "]\n",
    "gridCV2= GridSearchCV(my_pipe, grid2, cv=10, verbose=0)\n",
    "fit_grid2= gridCV2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;normalise&#x27;, StandardScaler()), (&#x27;model&#x27;, Ridge(alpha=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;normalise&#x27;, StandardScaler()), (&#x27;model&#x27;, Ridge(alpha=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('normalise', StandardScaler()), ('model', Ridge(alpha=1))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find Best hyperparameter for Ridge\n",
    "fit_grid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Ridge(alpha=1),\n",
       " 'model__alpha': 1,\n",
       " 'model__solver': 'auto',\n",
       " 'normalise': StandardScaler()}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find Best hyperparameter for Ridge\n",
    "fit_grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;normalise&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.05,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=4, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=180,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;normalise&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.05,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=4, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=180,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=180, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('normalise', StandardScaler()),\n",
       "                ('model',\n",
       "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                              colsample_bylevel=None, colsample_bynode=None,\n",
       "                              colsample_bytree=None, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              feature_types=None, gamma=None, gpu_id=None,\n",
       "                              grow_policy=None, importance_type=None,\n",
       "                              interaction_constraints=None, learning_rate=0.05,\n",
       "                              max_bin=None, max_cat_threshold=None,\n",
       "                              max_cat_to_onehot=None, max_delta_step=None,\n",
       "                              max_depth=4, max_leaves=None,\n",
       "                              min_child_weight=None, missing=nan,\n",
       "                              monotone_constraints=None, n_estimators=180,\n",
       "                              n_jobs=None, num_parallel_tree=None,\n",
       "                              predictor=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find Best hyperparameter for XGBoost\n",
    "fit_grid2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=180, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...),\n",
       " 'model__learning_rate': 0.05,\n",
       " 'model__max_depth': 4,\n",
       " 'model__n_estimators': 180,\n",
       " 'model__subsample': 0.9000000000000001,\n",
       " 'normalise': StandardScaler()}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge tuned hyperparameter Test Accuracy: 70.61371987326781\n"
     ]
    }
   ],
   "source": [
    "grid1_pred_test= np.round(fit_grid1.predict(X_test))\n",
    "print(f'Ridge tuned hyperparameter Test Accuracy: {define_late(y_true_test, grid1_pred_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test Accuracy: 72.08348938668502\n"
     ]
    }
   ],
   "source": [
    "print(f'XGBoost Test Accuracy: {define_late(y_true_test, np.round(fit_grid2.predict(X_test)))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the loss of  model after tuning hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge tuned loss= 0.8006579546719841\n",
      "XGboost tuned loss= 0.7612191393952891\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ridge tuned loss= {evaluate_loss(grid1_pred_test, y_true_test)}\")\n",
    "print(f\"XGboost tuned loss= {evaluate_loss(np.round(fit_grid2.predict(X_test)), y_true_test)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing the hyperparameter for XGboost and Ridge Regression, The output we have is:\n",
    "\n",
    "  | Model | Accurancy | Loss | \n",
    "  | ----------- | ----------- |----|\n",
    "  | Linear Regression | 70.6137 |0.8007 |\n",
    "  | Ridge Regression | 70.6187 |0.8007 |\n",
    "  | XGboost | 71.6037 |0.7583 |\n",
    "  | Neural Network | 72.0035 |0.7589 |\n",
    "  | Recurrent Neural Network | 71.9387 |0.8246 |\n",
    "  | Tuned hyperparameter Ridge Regression | 70.6137 |0.8007 |\n",
    "  | Tuned hyperparameter XGboost| 72.0835 |0.7612 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the XGboost model after tuned hyperparameter is bring the low loss and highest accuracy for the dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "The model successfully estimated the days needed to deliver packages for customers when they place orders. Around 28 percent of the predicted will be late, and the average error for the prediction is 0.76 days.\n",
    "\n",
    "In the future, these can improve the model's performance by looking for more impact features which can bring more information to the model.\n",
    "\n",
    "This model also can add an extra step to help businesses become aware of the possibility of being late by predicting the handling days and being able to give early warning to enterprises about which orders might be late and notify customers to be able to increase their experiences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
