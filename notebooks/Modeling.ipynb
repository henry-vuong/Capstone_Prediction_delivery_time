{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will only work with th data which already clean by the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#Model Import\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import svm\n",
    "#preprocessing import\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "#accuracy calculate import\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b2c_c2c</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>declared_handling_days</th>\n",
       "      <th>acceptance_scan_timestamp</th>\n",
       "      <th>shipment_method_id</th>\n",
       "      <th>shipping_fee</th>\n",
       "      <th>carrier_min_estimate</th>\n",
       "      <th>carrier_max_estimate</th>\n",
       "      <th>item_zip</th>\n",
       "      <th>buyer_zip</th>\n",
       "      <th>category_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>payment_datetime</th>\n",
       "      <th>delivery_date</th>\n",
       "      <th>weight</th>\n",
       "      <th>package_size</th>\n",
       "      <th>record_number</th>\n",
       "      <th>distance</th>\n",
       "      <th>handling_date</th>\n",
       "      <th>shipping_date</th>\n",
       "      <th>total_time</th>\n",
       "      <th>pay_year</th>\n",
       "      <th>pay_month</th>\n",
       "      <th>pay_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25454</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>97219</td>\n",
       "      <td>49040</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3002</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6727381</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-03</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11415-3528</td>\n",
       "      <td>62521</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1283</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>18507</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>27292</td>\n",
       "      <td>53010</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1104</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4677</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>90703</td>\n",
       "      <td>80022</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1353</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4677</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>90703</td>\n",
       "      <td>55070</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2456</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b2c_c2c  seller_id  declared_handling_days acceptance_scan_timestamp  \\\n",
       "0        1      25454                       3                2019-03-27   \n",
       "1        0    6727381                       2                2018-06-03   \n",
       "2        1      18507                       1                2019-01-08   \n",
       "3        1       4677                       1                2018-12-18   \n",
       "4        1       4677                       1                2018-07-28   \n",
       "\n",
       "   shipment_method_id  shipping_fee  carrier_min_estimate  \\\n",
       "0                   0             0                     3   \n",
       "1                   0             3                     3   \n",
       "2                   0             4                     3   \n",
       "3                   0             0                     3   \n",
       "4                   0             0                     3   \n",
       "\n",
       "   carrier_max_estimate    item_zip buyer_zip  category_id  item_price  \\\n",
       "0                     5       97219     49040           13          28   \n",
       "1                     5  11415-3528     62521            0          20   \n",
       "2                     5       27292     53010            1          20   \n",
       "3                     5       90703     80022            1          36   \n",
       "4                     5       90703     55070            1          25   \n",
       "\n",
       "   quantity payment_datetime delivery_date  weight  package_size  \\\n",
       "0         1       2019-03-24    2019-03-29       5             1   \n",
       "1         1       2018-06-02    2018-06-05       0             4   \n",
       "2         1       2019-01-06    2019-01-10       9             4   \n",
       "3         1       2018-12-17    2018-12-21       8             4   \n",
       "4         1       2018-07-27    2018-07-30       3             4   \n",
       "\n",
       "   record_number  distance  handling_date  shipping_date  total_time  \\\n",
       "0              1      3002              3              2           5   \n",
       "1              2      1283              1              2           3   \n",
       "2              3      1104              2              2           4   \n",
       "3              4      1353              1              3           4   \n",
       "4              5      2456              1              2           3   \n",
       "\n",
       "   pay_year  pay_month  pay_date  \n",
       "0      2019          3        24  \n",
       "1      2018          6         2  \n",
       "2      2019          1         6  \n",
       "3      2018         12        17  \n",
       "4      2018          7        27  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebay_clean= pd.read_csv('../data/cleaned/Ebay_cleaned.csv', index_col=0)\n",
    "pd.set_option('display.max_columns', None)\n",
    "ebay_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 296420 entries, 0 to 299999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   b2c_c2c                    296420 non-null  int64 \n",
      " 1   seller_id                  296420 non-null  int64 \n",
      " 2   declared_handling_days     296420 non-null  int64 \n",
      " 3   acceptance_scan_timestamp  296420 non-null  object\n",
      " 4   shipment_method_id         296420 non-null  int64 \n",
      " 5   shipping_fee               296420 non-null  int64 \n",
      " 6   carrier_min_estimate       296420 non-null  int64 \n",
      " 7   carrier_max_estimate       296420 non-null  int64 \n",
      " 8   item_zip                   296420 non-null  object\n",
      " 9   buyer_zip                  296420 non-null  object\n",
      " 10  category_id                296420 non-null  int64 \n",
      " 11  item_price                 296420 non-null  int64 \n",
      " 12  quantity                   296420 non-null  int64 \n",
      " 13  payment_datetime           296420 non-null  object\n",
      " 14  delivery_date              296420 non-null  object\n",
      " 15  weight                     296420 non-null  int64 \n",
      " 16  package_size               296420 non-null  int64 \n",
      " 17  record_number              296420 non-null  int64 \n",
      " 18  distance                   296420 non-null  int64 \n",
      " 19  handling_date              296420 non-null  int64 \n",
      " 20  shipping_date              296420 non-null  int64 \n",
      " 21  total_time                 296420 non-null  int64 \n",
      " 22  pay_year                   296420 non-null  int64 \n",
      " 23  pay_month                  296420 non-null  int64 \n",
      " 24  pay_date                   296420 non-null  int64 \n",
      "dtypes: int64(20), object(5)\n",
      "memory usage: 58.8+ MB\n"
     ]
    }
   ],
   "source": [
    "ebay_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= ebay_clean.drop(columns=['total_time','payment_datetime', 'delivery_date', 'acceptance_scan_timestamp', 'item_zip', 'buyer_zip', 'shipping_date', 'handling_date'])\n",
    "y= ebay_clean['total_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296420,)\n",
      "(296420, 17)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "X_train_ss= scaler.fit_transform(X_train, y_train)\n",
    "X_test_ss= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true= y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_late(pred, y_actual= y_true):\n",
    "    ontime= 0\n",
    "    late= 0\n",
    "    early= 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == y_true[i]:\n",
    "            ontime+=1\n",
    "        elif pred[i]> y_true[i]:\n",
    "            early+=1\n",
    "        else:\n",
    "            late+=1\n",
    "        \n",
    "    print(f'Ontime= {ontime}; {ontime/len(y_true)*100}')\n",
    "    print(f'Late= {late}; {late/len(y_true)*100}')\n",
    "    print(f'Early= {early}; {early/len(y_true)*100}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "pred > true-> early: \n",
    "pred = true-> ontime: \n",
    "pred < true-> late: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize\n",
    "linear_model= LinearRegression()\n",
    "#fit model\n",
    "linear_model.fit(X_train_ss, y_train)\n",
    "linear_preds= linear_model.predict(X_test_ss)\n",
    "linear_train_pred= linear_model.predict(X_train_ss)\n",
    "linear_train_pred= np.round(linear_train_pred)\n",
    "linear_preds= np.round(linear_preds)\n",
    "linear_score_test=  linear_model.score(X_test_ss, y_test)\n",
    "linear_score_train=  linear_model.score(X_train_ss, y_train)\n",
    "linear_accuracy_test= accuracy_score(y_test, linear_preds)\n",
    "linear_accuracy_train= accuracy_score(y_train, linear_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score test:  0.2226907766007692\n",
      "Accuracy score train: 0.22248414411982997\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy score test:  {linear_accuracy_test}')\n",
    "print(f'Accuracy score train: {linear_accuracy_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontime= 13202; 22.26907766007692\n",
      "Late= 17617; 29.716280952702245\n",
      "Early= 28465; 48.014641387220834\n"
     ]
    }
   ],
   "source": [
    "define_late(linear_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 window:\n",
    "\n",
    "1-3 days: 1\n",
    "4-7 days: 2\n",
    ">7 days: 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "ridge_model= Ridge(solver='lsqr')\n",
    "\n",
    "# fit\n",
    "ridge_model.fit(X_train_ss, y_train)\n",
    "ridge_preds= ridge_model.predict(X_test_ss)\n",
    "ridge_preds= np.round(ridge_preds)\n",
    "ridge_train_pred= ridge_model.predict(X_train_ss)\n",
    "ridge_train_pred= np.round(ridge_train_pred)\n",
    "ridge_score_test= ridge_model.score(X_test_ss, y_test)\n",
    "ridge_score_train= ridge_model.score(X_train_ss, y_train)\n",
    "ridge_accuracy_test= accuracy_score(y_test, ridge_preds)\n",
    "ridge_accuracy_train= accuracy_score(y_train, ridge_train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Accuracy score test:  0.22265704068551379\n",
      "Ridge Accuracy score train: 0.22248414411982997\n"
     ]
    }
   ],
   "source": [
    "print(f'Ridge Accuracy score test:  {ridge_accuracy_test}')\n",
    "print(f'Ridge Accuracy score train: {ridge_accuracy_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontime= 13200; 22.26570406855138\n",
      "Late= 17618; 29.717967748465018\n",
      "Early= 28466; 48.0163281829836\n"
     ]
    }
   ],
   "source": [
    "define_late(ridge_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.014641387220834"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ontime= 13202; 22.26907766007692\n",
    "Late= 17617; 29.716280952702245\n",
    "Early= 28465; 48.014641387220834"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.3261180310801296\n",
      "test score: 0.15258448775584488\n",
      "Test Accuracy : 0.23950813035557655\n",
      "Train Accuracy : 0.24550890628162741\n"
     ]
    }
   ],
   "source": [
    "# initialize \n",
    "xg_boost= XGBRegressor()\n",
    "#fit\n",
    "xg_boost.fit(X_train_ss, y_train)\n",
    "xg_pred= xg_boost.predict(X_test_ss)\n",
    "xg_pred= np.round(xg_pred)\n",
    "xg_train_pred= xg_boost.predict(X_train_ss)\n",
    "xg_train_pred= np.round(xg_train_pred)\n",
    "xg_train_accuracy=accuracy_score(y_train, xg_train_pred)\n",
    "xg_test_accuracy= accuracy_score(y_test, xg_pred)\n",
    "print(f'Train Score: {xg_boost.score(X_train_ss, y_train)}')\n",
    "print(f'test score: {xg_boost.score(X_test_ss, y_test)}')\n",
    "print(f'Test Accuracy : {xg_test_accuracy}')\n",
    "print(f'Train Accuracy : {xg_train_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontime= 14199; 23.950813035557655\n",
      "Late= 17166; 28.95553606369341\n",
      "Early= 27919; 47.09365090074893\n"
     ]
    }
   ],
   "source": [
    "define_late(xg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(preds, actual= y_true):\n",
    "    early_loss, late_loss = 0,0 \n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] < actual[i]:\n",
    "            #early shipment\n",
    "            early_loss += actual[i] - preds[i]\n",
    "        elif preds[i] > actual[i]:\n",
    "            #late shipment\n",
    "            late_loss += preds[i] - actual[i]\n",
    "    loss = (1/len(preds)) * (0.4 * (early_loss) + 0.6 * (late_loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rigde lost= 0.7799642399298293 -- linear loss= 0.7799709871128804 --xg lost= 0.736532622630052\n"
     ]
    }
   ],
   "source": [
    "print(f'rigde lost= {evaluate_loss(ridge_preds)} -- linear loss= {evaluate_loss(linear_preds)} --xg lost= {evaluate_loss(xg_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [linear_accuracy_test, linear_accuracy_train, ridge_accuracy_test, ridge_accuracy_train, xg_test_accuracy, xg_train_accuracy]\n",
    "columns=['linear test', 'linear train', 'ridge test', 'ridge train', 'xg test', 'xg train']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GRU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "tf.random.set_seed(123)\n",
    "# Create a new sequential model\n",
    "nn_model= keras.Sequential()\n",
    "regularizer= keras.regularizers.l2(0.02)\n",
    "#hidden layers\n",
    "nn_model.add(Dense(40, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(40, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "nn_model.add(Dense(40, activation=\"relu\", kernel_regularizer=regularizer))\n",
    "# nn_model.add(Dropout(0.2))\n",
    "#output layer\n",
    "nn_model.add(Dense(1))\n",
    "\n",
    "#compile nn_model\n",
    "nn_model.compile(\n",
    "     optimizer=keras.optimizers.Adam(),\n",
    "     loss=keras.losses.MeanSquaredError(),\n",
    "     metrics=[keras.metrics.BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 15:47:01.588222: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "history= nn_model.fit(X_train_ss, y_train, epochs=70, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853/1853 [==============================] - 0s 191us/step\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "NN_train_accuracy=history.history['binary_accuracy'][-1] \n",
    "result = nn_model.evaluate(X_test_ss,y_test, verbose=0)\n",
    "NN_pred = np.round(nn_model.predict(X_test_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontime= 13171; 22.21678699143108\n",
      "Late= 16814; 28.361783955198703\n",
      "Early= 29299; 49.42142905337022\n"
     ]
    }
   ],
   "source": [
    "define_late(NN_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237136, 17) (237136,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_ss.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make embedding\n",
    "number_class= X_train_ss.shape[1]\n",
    "embedding_dim= 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "\n",
    "#define rnn\n",
    "rnn_mode= keras.Sequential()\n",
    "# add layers\n",
    "embedding_layer=Embedding(number_class, embedding_dim)\n",
    "\n",
    "rnn_mode.add(LSTM(64, activation='relu', input_shape=(X_train_ss.shape[1], 1)))\n",
    "\n",
    "rnn_mode.add(Dense(64, activation= 'relu'))\n",
    "\n",
    "#output layer\n",
    "rnn_mode.add(Dense(1))\n",
    "\n",
    "# Compile mode\n",
    "rnn_mode.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer=Adam(learning_rate=0.02),\n",
    "    metrics='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5929/5929 [==============================] - 19s 3ms/step - loss: 710.0778 - accuracy: 0.0306 - val_loss: 8.5887 - val_accuracy: 0.0305\n",
      "Epoch 2/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.0117 - accuracy: 0.0307 - val_loss: 8.7712 - val_accuracy: 0.0305\n",
      "Epoch 3/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 8.8567 - accuracy: 0.0307 - val_loss: 7.9580 - val_accuracy: 0.0305\n",
      "Epoch 4/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.1137 - accuracy: 0.0307 - val_loss: 8.7007 - val_accuracy: 0.0305\n",
      "Epoch 5/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4174 - accuracy: 0.0307 - val_loss: 8.6986 - val_accuracy: 0.0305\n",
      "Epoch 6/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4165 - accuracy: 0.0307 - val_loss: 8.6974 - val_accuracy: 0.0305\n",
      "Epoch 7/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4171 - accuracy: 0.0307 - val_loss: 8.6978 - val_accuracy: 0.0305\n",
      "Epoch 8/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4166 - accuracy: 0.0307 - val_loss: 8.6976 - val_accuracy: 0.0305\n",
      "Epoch 9/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4160 - accuracy: 0.0307 - val_loss: 8.7268 - val_accuracy: 0.0305\n",
      "Epoch 10/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4164 - accuracy: 0.0307 - val_loss: 8.6978 - val_accuracy: 0.0305\n",
      "Epoch 11/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4167 - accuracy: 0.0307 - val_loss: 8.6996 - val_accuracy: 0.0305\n",
      "Epoch 12/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4169 - accuracy: 0.0307 - val_loss: 8.7184 - val_accuracy: 0.0305\n",
      "Epoch 13/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4169 - accuracy: 0.0307 - val_loss: 8.6982 - val_accuracy: 0.0305\n",
      "Epoch 14/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4167 - accuracy: 0.0307 - val_loss: 8.6969 - val_accuracy: 0.0305\n",
      "Epoch 15/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4167 - accuracy: 0.0307 - val_loss: 8.7047 - val_accuracy: 0.0305\n",
      "Epoch 16/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4157 - accuracy: 0.0307 - val_loss: 8.7062 - val_accuracy: 0.0305\n",
      "Epoch 17/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4156 - accuracy: 0.0307 - val_loss: 8.7110 - val_accuracy: 0.0305\n",
      "Epoch 18/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4165 - accuracy: 0.0307 - val_loss: 8.7049 - val_accuracy: 0.0305\n",
      "Epoch 19/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4171 - accuracy: 0.0307 - val_loss: 8.6968 - val_accuracy: 0.0305\n",
      "Epoch 20/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4157 - accuracy: 0.0307 - val_loss: 8.6969 - val_accuracy: 0.0305\n",
      "Epoch 21/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4164 - accuracy: 0.0307 - val_loss: 8.7047 - val_accuracy: 0.0305\n",
      "Epoch 22/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4156 - accuracy: 0.0307 - val_loss: 8.7044 - val_accuracy: 0.0305\n",
      "Epoch 23/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4177 - accuracy: 0.0307 - val_loss: 8.7011 - val_accuracy: 0.0305\n",
      "Epoch 24/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4159 - accuracy: 0.0307 - val_loss: 8.6980 - val_accuracy: 0.0305\n",
      "Epoch 25/50\n",
      "5929/5929 [==============================] - 20s 3ms/step - loss: 9.4168 - accuracy: 0.0307 - val_loss: 8.6985 - val_accuracy: 0.0305\n",
      "Epoch 26/50\n",
      "5929/5929 [==============================] - 19s 3ms/step - loss: 9.4168 - accuracy: 0.0307 - val_loss: 8.7011 - val_accuracy: 0.0305\n",
      "Epoch 27/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4177 - accuracy: 0.0307 - val_loss: 8.6976 - val_accuracy: 0.0305\n",
      "Epoch 28/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4170 - accuracy: 0.0307 - val_loss: 8.6997 - val_accuracy: 0.0305\n",
      "Epoch 29/50\n",
      "5929/5929 [==============================] - 17s 3ms/step - loss: 9.4155 - accuracy: 0.0307 - val_loss: 8.7399 - val_accuracy: 0.0305\n",
      "Epoch 30/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4149 - accuracy: 0.0307 - val_loss: 8.6968 - val_accuracy: 0.0305\n",
      "Epoch 31/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4153 - accuracy: 0.0307 - val_loss: 8.6969 - val_accuracy: 0.0305\n",
      "Epoch 32/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4170 - accuracy: 0.0307 - val_loss: 8.7051 - val_accuracy: 0.0305\n",
      "Epoch 33/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4161 - accuracy: 0.0307 - val_loss: 8.7089 - val_accuracy: 0.0305\n",
      "Epoch 34/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4164 - accuracy: 0.0307 - val_loss: 8.6973 - val_accuracy: 0.0305\n",
      "Epoch 35/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4167 - accuracy: 0.0307 - val_loss: 8.6970 - val_accuracy: 0.0305\n",
      "Epoch 36/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4165 - accuracy: 0.0307 - val_loss: 8.7048 - val_accuracy: 0.0305\n",
      "Epoch 37/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4166 - accuracy: 0.0307 - val_loss: 8.6986 - val_accuracy: 0.0305\n",
      "Epoch 38/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4166 - accuracy: 0.0307 - val_loss: 8.6970 - val_accuracy: 0.0305\n",
      "Epoch 39/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4163 - accuracy: 0.0307 - val_loss: 8.7096 - val_accuracy: 0.0305\n",
      "Epoch 40/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4159 - accuracy: 0.0307 - val_loss: 8.7130 - val_accuracy: 0.0305\n",
      "Epoch 41/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4169 - accuracy: 0.0307 - val_loss: 8.6983 - val_accuracy: 0.0305\n",
      "Epoch 42/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4158 - accuracy: 0.0307 - val_loss: 8.7132 - val_accuracy: 0.0305\n",
      "Epoch 43/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4159 - accuracy: 0.0307 - val_loss: 8.6969 - val_accuracy: 0.0305\n",
      "Epoch 44/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4162 - accuracy: 0.0307 - val_loss: 8.6997 - val_accuracy: 0.0305\n",
      "Epoch 45/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4154 - accuracy: 0.0307 - val_loss: 8.6968 - val_accuracy: 0.0305\n",
      "Epoch 46/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4161 - accuracy: 0.0307 - val_loss: 8.7002 - val_accuracy: 0.0305\n",
      "Epoch 47/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4169 - accuracy: 0.0307 - val_loss: 8.6990 - val_accuracy: 0.0305\n",
      "Epoch 48/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4160 - accuracy: 0.0307 - val_loss: 8.6970 - val_accuracy: 0.0305\n",
      "Epoch 49/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4165 - accuracy: 0.0307 - val_loss: 8.7007 - val_accuracy: 0.0305\n",
      "Epoch 50/50\n",
      "5929/5929 [==============================] - 18s 3ms/step - loss: 9.4167 - accuracy: 0.0307 - val_loss: 8.6973 - val_accuracy: 0.0305\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "rnn_history= rnn_mode.fit(X_train_ss, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853/1853 [==============================] - 2s 884us/step - loss: 10.1200 - accuracy: 0.0302\n",
      "1853/1853 [==============================] - 2s 833us/step\n"
     ]
    }
   ],
   "source": [
    "rnn_train_accu= rnn_history.history['accuracy'][-1]\n",
    "result= rnn_mode.evaluate(X_test_ss, y_test)\n",
    "rnn_pred= np.round(rnn_mode.predict(X_test_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 64)                16896     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,121\n",
      "Trainable params: 21,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_mode.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_train= 0.03068399801850319\n",
      "evaluate; =[10.119983673095703, 0.030193643644452095]\n",
      "predic= [[4.]\n",
      " [4.]\n",
      " [4.]\n",
      " ...\n",
      " [4.]\n",
      " [4.]\n",
      " [4.]]\n",
      "Ontime= 11591; 19.55164968625599\n",
      "Late= 16630; 28.0514135348492\n",
      "Early= 31063; 52.39693677889481\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy_train= {rnn_train_accu}')\n",
    "print(f'evaluate; ={result}')\n",
    "print(f'predic= {rnn_pred}')\n",
    "define_late(rnn_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline - GridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[22], line 29\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m grid\u001b[39m=\u001b[39m [\n",
      "\u001b[1;32m      8\u001b[0m     \u001b[39m# {\u001b[39;00m\n",
      "\u001b[1;32m      9\u001b[0m     \u001b[39m#     'model': [svm.SVC()],\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     26\u001b[0m     }\n",
      "\u001b[1;32m     27\u001b[0m ]\n",
      "\u001b[1;32m     28\u001b[0m gridCV\u001b[39m=\u001b[39m GridSearchCV(my_pipe, grid)\n",
      "\u001b[0;32m---> 29\u001b[0m fit_grid\u001b[39m=\u001b[39m gridCV\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n",
      "\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n",
      "\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n",
      "\u001b[1;32m    870\u001b[0m     )\n",
      "\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n",
      "\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n",
      "\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n",
      "\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n",
      "\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n",
      "\u001b[1;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n",
      "\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n",
      "\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n",
      "\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n",
      "\u001b[1;32m    818\u001b[0m         )\n",
      "\u001b[1;32m    819\u001b[0m     )\n",
      "\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n",
      "\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n",
      "\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n",
      "\u001b[1;32m    824\u001b[0m         X,\n",
      "\u001b[1;32m    825\u001b[0m         y,\n",
      "\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n",
      "\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n",
      "\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n",
      "\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n",
      "\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n",
      "\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n",
      "\u001b[1;32m    832\u001b[0m     )\n",
      "\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n",
      "\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n",
      "\u001b[1;32m    835\u001b[0m     )\n",
      "\u001b[1;32m    836\u001b[0m )\n",
      "\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    843\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n",
      "\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n",
      "\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n",
      "\u001b[1;32m     62\u001b[0m )\n",
      "\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n",
      "\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n",
      "\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n",
      "\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n",
      "\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n",
      "\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n",
      "\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n",
      "\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n",
      "\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n",
      "\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n",
      "\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n",
      "\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n",
      "\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n",
      "\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n",
      "\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n",
      "\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n",
      "\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n",
      "\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n",
      "\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n",
      "\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n",
      "\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n",
      "\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n",
      "\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n",
      "\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n",
      "\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n",
      "\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n",
      "\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n",
      "\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n",
      "\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n",
      "\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n",
      "\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n",
      "\u001b[1;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n",
      "\u001b[0;32m--> 405\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n",
      "\u001b[1;32m    407\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n",
      "\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n",
      "\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n",
      "\u001b[1;32m   1014\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m   1016\u001b[0m (\n",
      "\u001b[1;32m   1017\u001b[0m     model,\n",
      "\u001b[1;32m   1018\u001b[0m     metric,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n",
      "\u001b[1;32m   1024\u001b[0m )\n",
      "\u001b[0;32m-> 1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n",
      "\u001b[1;32m   1026\u001b[0m     params,\n",
      "\u001b[1;32m   1027\u001b[0m     train_dmatrix,\n",
      "\u001b[1;32m   1028\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n",
      "\u001b[1;32m   1029\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n",
      "\u001b[1;32m   1030\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n",
      "\u001b[1;32m   1031\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n",
      "\u001b[1;32m   1032\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n",
      "\u001b[1;32m   1033\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n",
      "\u001b[1;32m   1034\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n",
      "\u001b[1;32m   1035\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n",
      "\u001b[1;32m   1036\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n",
      "\u001b[1;32m   1037\u001b[0m )\n",
      "\u001b[1;32m   1039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n",
      "\u001b[1;32m   1040\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n",
      "\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n",
      "\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n",
      "\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n",
      "\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n",
      "\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n",
      "\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n",
      "\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n",
      "\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n",
      "\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n",
      "\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n",
      "\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimators= [\n",
    "    ('normalise', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "] \n",
    "my_pipe= Pipeline(estimators)\n",
    "\n",
    "grid= [\n",
    "    {\n",
    "        'model': [Ridge()],\n",
    "        'normalise':[StandardScaler()],\n",
    "        'model__solver':['aoto', 'lbfgs', 'lsqr']\n",
    "    },\n",
    "    {\n",
    "        'model':[keras.Sequential()],\n",
    "        'normalise':[StandardScaler()],\n",
    "        'model__add':[]\n",
    "\n",
    "    }, \n",
    "    {\n",
    "        'model':[XGBRegressor()],\n",
    "        'normalise':[StandardScaler()],\n",
    "        'model__max_depth': range (2, 10, 1),\n",
    "        'model__n_estimators': range(60, 220, 40),\n",
    "        'model__learning_rate': [0.1, 0.01, 0.05]\n",
    "    }\n",
    "]\n",
    "gridCV= GridSearchCV(my_pipe, grid, cv=5)\n",
    "fit_grid= gridCV.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
